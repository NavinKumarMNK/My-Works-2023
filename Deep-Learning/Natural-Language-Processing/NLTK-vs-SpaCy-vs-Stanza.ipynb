{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5353a75",
   "metadata": {},
   "source": [
    "# **NLTK vs Spacy vs Stanford CoreNLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f247e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Navin Kumar M 20BAI1094\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.10\n",
      "IPython version      : 7.34.0\n",
      "\n",
      "nltk  : 3.8.1\n",
      "spacy : 3.5.2\n",
      "stanza: 1.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Navin Kumar M 20BAI1094' -v -p nltk,spacy,stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd2969a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dffb1c9beb948a581fbd5fd2197508b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 11:14:26 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-08-30 11:14:27 INFO: File exists: /root/stanza_resources/en/default.zip\n",
      "2023-08-30 11:14:32 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
      "2023-08-30 11:14:32 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a0dc943b3c429ebec211f1ba35058a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 11:14:33 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-08-30 11:14:33 INFO: Using device: cuda\n",
      "2023-08-30 11:14:33 INFO: Loading: tokenize\n",
      "2023-08-30 11:14:33 INFO: Loading: pos\n",
      "2023-08-30 11:14:33 INFO: Loading: lemma\n",
      "2023-08-30 11:14:33 INFO: Loading: constituency\n",
      "2023-08-30 11:14:34 INFO: Loading: depparse\n",
      "2023-08-30 11:14:34 INFO: Loading: sentiment\n",
      "2023-08-30 11:14:34 INFO: Loading: ner\n",
      "2023-08-30 11:14:35 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import stanza\n",
    "import spacy\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "stanza.download('en')\n",
    "nlp_stz = stanza.Pipeline('en')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2ce4df",
   "metadata": {},
   "source": [
    "## **POS Tagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aecf4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"She sells seashells by the seashore.\",\n",
    "    \"The cat is sitting on the windowsill.\",\n",
    "    \"I enjoy reading books in the evening.\",\n",
    "    \"They are cooking dinner in the kitchen.\",\n",
    "    \"He played the guitar at the concert.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4139ca5",
   "metadata": {},
   "source": [
    "### **NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbdc64bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "POS Tags: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n",
      "Sentence: She sells seashells by the seashore.\n",
      "POS Tags: [('She', 'PRP'), ('sells', 'VBZ'), ('seashells', 'NNS'), ('by', 'IN'), ('the', 'DT'), ('seashore', 'NN'), ('.', '.')]\n",
      "Sentence: The cat is sitting on the windowsill.\n",
      "POS Tags: [('The', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('windowsill', 'NN'), ('.', '.')]\n",
      "Sentence: I enjoy reading books in the evening.\n",
      "POS Tags: [('I', 'PRP'), ('enjoy', 'VBP'), ('reading', 'VBG'), ('books', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('evening', 'NN'), ('.', '.')]\n",
      "Sentence: They are cooking dinner in the kitchen.\n",
      "POS Tags: [('They', 'PRP'), ('are', 'VBP'), ('cooking', 'VBG'), ('dinner', 'NN'), ('in', 'IN'), ('the', 'DT'), ('kitchen', 'NN'), ('.', '.')]\n",
      "Sentence: He played the guitar at the concert.\n",
      "POS Tags: [('He', 'PRP'), ('played', 'VBD'), ('the', 'DT'), ('guitar', 'NN'), ('at', 'IN'), ('the', 'DT'), ('concert', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"POS Tags:\", pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f032027",
   "metadata": {},
   "source": [
    "### **Spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa04a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "The DET\n",
      "quick ADJ\n",
      "brown ADJ\n",
      "fox NOUN\n",
      "jumps VERB\n",
      "over ADP\n",
      "the DET\n",
      "lazy ADJ\n",
      "dog NOUN\n",
      ". PUNCT\n",
      "Sentence: She sells seashells by the seashore.\n",
      "She PRON\n",
      "sells VERB\n",
      "seashells NOUN\n",
      "by ADP\n",
      "the DET\n",
      "seashore NOUN\n",
      ". PUNCT\n",
      "Sentence: The cat is sitting on the windowsill.\n",
      "The DET\n",
      "cat NOUN\n",
      "is AUX\n",
      "sitting VERB\n",
      "on ADP\n",
      "the DET\n",
      "windowsill NOUN\n",
      ". PUNCT\n",
      "Sentence: I enjoy reading books in the evening.\n",
      "I PRON\n",
      "enjoy VERB\n",
      "reading VERB\n",
      "books NOUN\n",
      "in ADP\n",
      "the DET\n",
      "evening NOUN\n",
      ". PUNCT\n",
      "Sentence: They are cooking dinner in the kitchen.\n",
      "They PRON\n",
      "are AUX\n",
      "cooking VERB\n",
      "dinner NOUN\n",
      "in ADP\n",
      "the DET\n",
      "kitchen NOUN\n",
      ". PUNCT\n",
      "Sentence: He played the guitar at the concert.\n",
      "He PRON\n",
      "played VERB\n",
      "the DET\n",
      "guitar NOUN\n",
      "at ADP\n",
      "the DET\n",
      "concert NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    print(\"Sentence:\", sentence)\n",
    "    for token in doc:\n",
    "        print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79188359",
   "metadata": {},
   "source": [
    "### **Stanford NLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c36bcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "The DET\n",
      "quick ADJ\n",
      "brown ADJ\n",
      "fox NOUN\n",
      "jumps VERB\n",
      "over ADP\n",
      "the DET\n",
      "lazy ADJ\n",
      "dog NOUN\n",
      ". PUNCT\n",
      "\n",
      "Sentence: She sells seashells by the seashore.\n",
      "She PRON\n",
      "sells VERB\n",
      "seashells NOUN\n",
      "by ADP\n",
      "the DET\n",
      "seashore NOUN\n",
      ". PUNCT\n",
      "\n",
      "Sentence: The cat is sitting on the windowsill.\n",
      "The DET\n",
      "cat NOUN\n",
      "is AUX\n",
      "sitting VERB\n",
      "on ADP\n",
      "the DET\n",
      "windowsill NOUN\n",
      ". PUNCT\n",
      "\n",
      "Sentence: I enjoy reading books in the evening.\n",
      "I PRON\n",
      "enjoy VERB\n",
      "reading VERB\n",
      "books NOUN\n",
      "in ADP\n",
      "the DET\n",
      "evening NOUN\n",
      ". PUNCT\n",
      "\n",
      "Sentence: They are cooking dinner in the kitchen.\n",
      "They PRON\n",
      "are AUX\n",
      "cooking VERB\n",
      "dinner NOUN\n",
      "in ADP\n",
      "the DET\n",
      "kitchen NOUN\n",
      ". PUNCT\n",
      "\n",
      "Sentence: He played the guitar at the concert.\n",
      "He PRON\n",
      "played VERB\n",
      "the DET\n",
      "guitar NOUN\n",
      "at ADP\n",
      "the DET\n",
      "concert NOUN\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp_stz(sentence)\n",
    "    print(\"Sentence:\", sentence)\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            print(word.text, word.pos)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c4208",
   "metadata": {},
   "source": [
    "## **Named Entity Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6ee51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Apple Inc. is headquartered in Cupertino, California.\",\n",
    "    \"The Eiffel Tower is located in Paris, France.\",\n",
    "    \"Albert Einstein was born in Ulm, Germany.\",\n",
    "    \"Microsoft was founded by Bill Gates and Paul Allen.\",\n",
    "    \"The Mona Lisa is displayed at the Louvre Museum in Paris.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf2aa6",
   "metadata": {},
   "source": [
    "### **NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b80aa89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Apple Inc. is headquartered in Cupertino, California.\n",
      "NER Tags: (S\n",
      "  (PERSON Apple/NNP)\n",
      "  (ORGANIZATION Inc./NNP)\n",
      "  is/VBZ\n",
      "  headquartered/VBN\n",
      "  in/IN\n",
      "  (GPE Cupertino/NNP)\n",
      "  ,/,\n",
      "  (GPE California/NNP)\n",
      "  ./.)\n",
      "Sentence: The Eiffel Tower is located in Paris, France.\n",
      "NER Tags: (S\n",
      "  The/DT\n",
      "  (ORGANIZATION Eiffel/NNP Tower/NNP)\n",
      "  is/VBZ\n",
      "  located/VBN\n",
      "  in/IN\n",
      "  (GPE Paris/NNP)\n",
      "  ,/,\n",
      "  (GPE France/NNP)\n",
      "  ./.)\n",
      "Sentence: Albert Einstein was born in Ulm, Germany.\n",
      "NER Tags: (S\n",
      "  (PERSON Albert/NNP)\n",
      "  (PERSON Einstein/NNP)\n",
      "  was/VBD\n",
      "  born/VBN\n",
      "  in/IN\n",
      "  (GPE Ulm/NNP)\n",
      "  ,/,\n",
      "  (GPE Germany/NNP)\n",
      "  ./.)\n",
      "Sentence: Microsoft was founded by Bill Gates and Paul Allen.\n",
      "NER Tags: (S\n",
      "  (PERSON Microsoft/NNP)\n",
      "  was/VBD\n",
      "  founded/VBN\n",
      "  by/IN\n",
      "  (PERSON Bill/NNP Gates/NNP)\n",
      "  and/CC\n",
      "  (PERSON Paul/NNP Allen/NNP)\n",
      "  ./.)\n",
      "Sentence: The Mona Lisa is displayed at the Louvre Museum in Paris.\n",
      "NER Tags: (S\n",
      "  The/DT\n",
      "  (ORGANIZATION Mona/NNP Lisa/NNP)\n",
      "  is/VBZ\n",
      "  displayed/VBN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Louvre/NNP Museum/NNP)\n",
      "  in/IN\n",
      "  (GPE Paris/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    ner_tags = nltk.ne_chunk(nltk.pos_tag(words))\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"NER Tags:\", ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e07eab9",
   "metadata": {},
   "source": [
    "### **Spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f6da6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Apple Inc. is headquartered in Cupertino, California.\n",
      "Apple Inc. ORG\n",
      "Cupertino GPE\n",
      "California GPE\n",
      "Sentence: The Eiffel Tower is located in Paris, France.\n",
      "The Eiffel Tower FAC\n",
      "Paris GPE\n",
      "France GPE\n",
      "Sentence: Albert Einstein was born in Ulm, Germany.\n",
      "Albert Einstein PERSON\n",
      "Ulm GPE\n",
      "Germany GPE\n",
      "Sentence: Microsoft was founded by Bill Gates and Paul Allen.\n",
      "Microsoft ORG\n",
      "Bill Gates PERSON\n",
      "Paul Allen PERSON\n",
      "Sentence: The Mona Lisa is displayed at the Louvre Museum in Paris.\n",
      "the Louvre Museum ORG\n",
      "Paris GPE\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    print(\"Sentence:\", sentence)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9433c231",
   "metadata": {},
   "source": [
    "### **Stanford NLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8eb1e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Apple Inc. is headquartered in Cupertino, California.\n",
      "Apple Inc. ORG\n",
      "Cupertino GPE\n",
      "California GPE\n",
      "Sentence: The Eiffel Tower is located in Paris, France.\n",
      "The Eiffel Tower FAC\n",
      "Paris GPE\n",
      "France GPE\n",
      "Sentence: Albert Einstein was born in Ulm, Germany.\n",
      "Albert Einstein PERSON\n",
      "Ulm GPE\n",
      "Germany GPE\n",
      "Sentence: Microsoft was founded by Bill Gates and Paul Allen.\n",
      "Microsoft ORG\n",
      "Bill Gates PERSON\n",
      "Paul Allen PERSON\n",
      "Sentence: The Mona Lisa is displayed at the Louvre Museum in Paris.\n",
      "The Mona Lisa WORK_OF_ART\n",
      "the Louvre Museum FAC\n",
      "Paris GPE\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp_stz(sentence)\n",
    "    print(\"Sentence:\", sentence)\n",
    "    for sent in doc.sentences:\n",
    "        for ent in sent.ents:\n",
    "            print(ent.text, ent.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acbe7ba",
   "metadata": {},
   "source": [
    "## **Chunking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8e47acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The big brown dog barked loudly.\",\n",
    "    \"She saw a beautiful sunset at the beach.\",\n",
    "    \"John read a book in the park.\",\n",
    "    \"The cat chased the mouse under the table.\",\n",
    "    \"They built a new bridge across the river.\"\n",
    "]\n",
    "\n",
    "grammar = r\"\"\"\n",
    "    NP: {<DT|JJ|NN.*>+}\n",
    "    VP: {<VB.*><NP|PP|CLAUSE>+}\n",
    "    CLAUSE: {<NP><VP>}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bdc2b6",
   "metadata": {},
   "source": [
    "### **NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e640cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The big brown dog barked loudly.\n",
      "Chunked Tree: (S (NP The/DT big/JJ brown/NN dog/NN) barked/VBD loudly/RB ./.)\n",
      "Sentence: She saw a beautiful sunset at the beach.\n",
      "Chunked Tree: (S\n",
      "  She/PRP\n",
      "  (VP saw/VBD (NP a/DT beautiful/JJ sunset/NN))\n",
      "  at/IN\n",
      "  (NP the/DT beach/NN)\n",
      "  ./.)\n",
      "Sentence: John read a book in the park.\n",
      "Chunked Tree: (S\n",
      "  (CLAUSE (NP John/NNP) (VP read/VBD (NP a/DT book/NN)))\n",
      "  in/IN\n",
      "  (NP the/DT park/NN)\n",
      "  ./.)\n",
      "Sentence: The cat chased the mouse under the table.\n",
      "Chunked Tree: (S\n",
      "  (CLAUSE (NP The/DT cat/NN) (VP chased/VBD (NP the/DT mouse/NN)))\n",
      "  under/IN\n",
      "  (NP the/DT table/NN)\n",
      "  ./.)\n",
      "Sentence: They built a new bridge across the river.\n",
      "Chunked Tree: (S\n",
      "  They/PRP\n",
      "  (VP built/VBD (NP a/DT new/JJ bridge/NN))\n",
      "  across/IN\n",
      "  (NP the/DT river/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "chunk_parser = nltk.RegexpParser(grammar)\n",
    "\n",
    "# Perform chunking for each sentence\n",
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    chunked_tree = chunk_parser.parse(pos_tags)\n",
    "\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Chunked Tree:\", chunked_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0aaee",
   "metadata": {},
   "source": [
    "### **Spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f85cce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The big brown dog barked loudly.\n",
      "The the\n",
      "big big\n",
      "brown brown\n",
      "dog dog\n",
      "barked bark\n",
      "loudly loudly\n",
      ". .\n",
      "Sentence: She saw a beautiful sunset at the beach.\n",
      "She she\n",
      "saw see\n",
      "a a\n",
      "beautiful beautiful\n",
      "sunset sunset\n",
      "at at\n",
      "the the\n",
      "beach beach\n",
      ". .\n",
      "Sentence: John read a book in the park.\n",
      "John John\n",
      "read read\n",
      "a a\n",
      "book book\n",
      "in in\n",
      "the the\n",
      "park park\n",
      ". .\n",
      "Sentence: The cat chased the mouse under the table.\n",
      "The the\n",
      "cat cat\n",
      "chased chase\n",
      "the the\n",
      "mouse mouse\n",
      "under under\n",
      "the the\n",
      "table table\n",
      ". .\n",
      "Sentence: They built a new bridge across the river.\n",
      "They they\n",
      "built build\n",
      "a a\n",
      "new new\n",
      "bridge bridge\n",
      "across across\n",
      "the the\n",
      "river river\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    print(\"Sentence:\", sentence)\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e785c55",
   "metadata": {},
   "source": [
    "### **Stanford NLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc503e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The big brown dog barked loudly.\n",
      "The the\n",
      "big big\n",
      "brown brown\n",
      "dog dog\n",
      "barked bark\n",
      "loudly loudly\n",
      ". .\n",
      "\n",
      "Sentence: She saw a beautiful sunset at the beach.\n",
      "She she\n",
      "saw see\n",
      "a a\n",
      "beautiful beautiful\n",
      "sunset sunset\n",
      "at at\n",
      "the the\n",
      "beach beach\n",
      ". .\n",
      "\n",
      "Sentence: John read a book in the park.\n",
      "John John\n",
      "read read\n",
      "a a\n",
      "book book\n",
      "in in\n",
      "the the\n",
      "park park\n",
      ". .\n",
      "\n",
      "Sentence: The cat chased the mouse under the table.\n",
      "The the\n",
      "cat cat\n",
      "chased chase\n",
      "the the\n",
      "mouse mouse\n",
      "under under\n",
      "the the\n",
      "table table\n",
      ". .\n",
      "\n",
      "Sentence: They built a new bridge across the river.\n",
      "They they\n",
      "built build\n",
      "a a\n",
      "new new\n",
      "bridge bridge\n",
      "across across\n",
      "the the\n",
      "river river\n",
      ". .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp_stz(sentence)\n",
    "    print(\"Sentence:\", sentence)\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            print(word.text, word.lemma)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
