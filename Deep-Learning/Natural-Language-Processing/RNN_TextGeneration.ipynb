{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GoT7pePqfD9"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UydERZ-AeVYq"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ow6j6HtUqlYu"
   },
   "source": [
    "### Downloading the Shakespeare dataset and Exploring it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGggj9apenou",
    "outputId": "c7d7d3e5-864c-4954-a8f5-46ec5ef32206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_url = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "dataset_text = open(data_url, 'rb').read().decode(encoding='utf-8')\n",
    "print(dataset_text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlsWrKfDe8AL",
    "outputId": "1a32339f-3626-49c8-d72a-6b0784643fba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oc2TRaC3fH3R",
    "outputId": "c3ed4c86-689a-42bf-c24d-1dc0001beaa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "# obtain the unique characters in the dataset and print out their length\n",
    "vocab = sorted(set(dataset_text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jde8EHvZfLka",
    "outputId": "b966bb48-1661-41cd-dacc-c9443b0e4979"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7RwUS2Nqycg"
   },
   "source": [
    "### Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syMWm17mfPBN",
    "outputId": "876cf695-9307-40ac-d229-bdbc5a009633"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '3': 9,\n",
       " ':': 10,\n",
       " ';': 11,\n",
       " '?': 12,\n",
       " 'A': 13,\n",
       " 'B': 14,\n",
       " 'C': 15,\n",
       " 'D': 16,\n",
       " 'E': 17,\n",
       " 'F': 18,\n",
       " 'G': 19,\n",
       " 'H': 20,\n",
       " 'I': 21,\n",
       " 'J': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'U': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'X': 36,\n",
       " 'Y': 37,\n",
       " 'Z': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {char:index for index, char in enumerate(vocab)}\n",
    "char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "riOGEpAxfYWa",
    "outputId": "03c1bbb9-073b-4f79-bff7-9ab0b10588fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: ' ',\n",
       " 2: '!',\n",
       " 3: '$',\n",
       " 4: '&',\n",
       " 5: \"'\",\n",
       " 6: ',',\n",
       " 7: '-',\n",
       " 8: '.',\n",
       " 9: '3',\n",
       " 10: ':',\n",
       " 11: ';',\n",
       " 12: '?',\n",
       " 13: 'A',\n",
       " 14: 'B',\n",
       " 15: 'C',\n",
       " 16: 'D',\n",
       " 17: 'E',\n",
       " 18: 'F',\n",
       " 19: 'G',\n",
       " 20: 'H',\n",
       " 21: 'I',\n",
       " 22: 'J',\n",
       " 23: 'K',\n",
       " 24: 'L',\n",
       " 25: 'M',\n",
       " 26: 'N',\n",
       " 27: 'O',\n",
       " 28: 'P',\n",
       " 29: 'Q',\n",
       " 30: 'R',\n",
       " 31: 'S',\n",
       " 32: 'T',\n",
       " 33: 'U',\n",
       " 34: 'V',\n",
       " 35: 'W',\n",
       " 36: 'X',\n",
       " 37: 'Y',\n",
       " 38: 'Z',\n",
       " 39: 'a',\n",
       " 40: 'b',\n",
       " 41: 'c',\n",
       " 42: 'd',\n",
       " 43: 'e',\n",
       " 44: 'f',\n",
       " 45: 'g',\n",
       " 46: 'h',\n",
       " 47: 'i',\n",
       " 48: 'j',\n",
       " 49: 'k',\n",
       " 50: 'l',\n",
       " 51: 'm',\n",
       " 52: 'n',\n",
       " 53: 'o',\n",
       " 54: 'p',\n",
       " 55: 'q',\n",
       " 56: 'r',\n",
       " 57: 's',\n",
       " 58: 't',\n",
       " 59: 'u',\n",
       " 60: 'v',\n",
       " 61: 'w',\n",
       " 62: 'x',\n",
       " 63: 'y',\n",
       " 64: 'z'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char = {index:char for index, char in enumerate(vocab)}\n",
    "idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZ64SqOCflIg",
    "outputId": "01414a49-3512-49b9-8614-b4862af659f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18,\n",
       " 47,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 1,\n",
       " 15,\n",
       " 47,\n",
       " 58,\n",
       " 47,\n",
       " 64,\n",
       " 43,\n",
       " 52,\n",
       " 10,\n",
       " 0,\n",
       " 14,\n",
       " 43,\n",
       " 44,\n",
       " 53,\n",
       " 56,\n",
       " 43,\n",
       " 1,\n",
       " 61,\n",
       " 43,\n",
       " 1,\n",
       " 54,\n",
       " 56,\n",
       " 53,\n",
       " 41,\n",
       " 43,\n",
       " 43,\n",
       " 42,\n",
       " 1,\n",
       " 39,\n",
       " 52,\n",
       " 63,\n",
       " 1,\n",
       " 44,\n",
       " 59,\n",
       " 56,\n",
       " 58,\n",
       " 46,\n",
       " 43,\n",
       " 56,\n",
       " 6,\n",
       " 1,\n",
       " 46,\n",
       " 43,\n",
       " 39,\n",
       " 56,\n",
       " 1,\n",
       " 51,\n",
       " 43,\n",
       " 1,\n",
       " 57,\n",
       " 54,\n",
       " 43,\n",
       " 39,\n",
       " 49,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 13,\n",
       " 50,\n",
       " 50,\n",
       " 10,\n",
       " 0,\n",
       " 31,\n",
       " 54,\n",
       " 43,\n",
       " 39,\n",
       " 49,\n",
       " 6,\n",
       " 1,\n",
       " 57,\n",
       " 54,\n",
       " 43,\n",
       " 39,\n",
       " 49,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 18,\n",
       " 47,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 1,\n",
       " 15,\n",
       " 47,\n",
       " 58,\n",
       " 47,\n",
       " 64,\n",
       " 43,\n",
       " 52,\n",
       " 10,\n",
       " 0,\n",
       " 37,\n",
       " 53,\n",
       " 59,\n",
       " 1,\n",
       " 39,\n",
       " 56,\n",
       " 43,\n",
       " 1,\n",
       " 39,\n",
       " 50,\n",
       " 50,\n",
       " 1,\n",
       " 56,\n",
       " 43,\n",
       " 57,\n",
       " 53,\n",
       " 50,\n",
       " 60,\n",
       " 43,\n",
       " 42,\n",
       " 1,\n",
       " 56,\n",
       " 39,\n",
       " 58,\n",
       " 46,\n",
       " 43,\n",
       " 56,\n",
       " 1,\n",
       " 58,\n",
       " 53,\n",
       " 1,\n",
       " 42,\n",
       " 47,\n",
       " 43,\n",
       " 1,\n",
       " 58,\n",
       " 46,\n",
       " 39,\n",
       " 52,\n",
       " 1,\n",
       " 58,\n",
       " 53,\n",
       " 1,\n",
       " 44,\n",
       " 39,\n",
       " 51,\n",
       " 47,\n",
       " 57,\n",
       " 46,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 13,\n",
       " 50,\n",
       " 50,\n",
       " 10,\n",
       " 0,\n",
       " 30,\n",
       " 43,\n",
       " 57,\n",
       " 53,\n",
       " 50,\n",
       " 60,\n",
       " 43,\n",
       " 42,\n",
       " 8,\n",
       " 1,\n",
       " 56,\n",
       " 43,\n",
       " 57,\n",
       " 53,\n",
       " 50,\n",
       " 60,\n",
       " 43,\n",
       " 42,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 18,\n",
       " 47,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 1,\n",
       " 15,\n",
       " 47,\n",
       " 58,\n",
       " 47,\n",
       " 64,\n",
       " 43,\n",
       " 52,\n",
       " 10,\n",
       " 0,\n",
       " 18,\n",
       " 47,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 6,\n",
       " 1,\n",
       " 63,\n",
       " 53,\n",
       " 59,\n",
       " 1,\n",
       " 49,\n",
       " 52,\n",
       " 53,\n",
       " 61,\n",
       " 1,\n",
       " 15,\n",
       " 39,\n",
       " 47,\n",
       " 59,\n",
       " 57,\n",
       " 1,\n",
       " 25,\n",
       " 39,\n",
       " 56,\n",
       " 41,\n",
       " 47,\n",
       " 59,\n",
       " 57,\n",
       " 1,\n",
       " 47,\n",
       " 57,\n",
       " 1,\n",
       " 41,\n",
       " 46,\n",
       " 47,\n",
       " 43,\n",
       " 44,\n",
       " 1,\n",
       " 43,\n",
       " 52,\n",
       " 43,\n",
       " 51,\n",
       " 63,\n",
       " 1,\n",
       " 58,\n",
       " 53,\n",
       " 1,\n",
       " 58,\n",
       " 46,\n",
       " 43,\n",
       " 1,\n",
       " 54,\n",
       " 43,\n",
       " 53,\n",
       " 54,\n",
       " 50,\n",
       " 43,\n",
       " 8,\n",
       " 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dataset from 'characters' to 'integers'\n",
    "text_as_int = [char2idx[char] for char in dataset_text]\n",
    "text_as_int[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CHF_khodhU-1"
   },
   "outputs": [],
   "source": [
    "# converting the text vector into a stream of character indices using from_tensor_slices function from tf.data.dataset\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2G1sb-_hlLM",
    "outputId": "7e7c9fe9-780c-4592-e5d3-18d5410fa25b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "C\n",
      "i\n",
      "t\n",
      "i\n",
      "z\n",
      "e\n",
      "n\n",
      ":\n",
      "\n",
      "\n",
      "B\n",
      "e\n",
      "f\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "n\n",
      "y\n",
      " \n",
      "f\n",
      "u\n",
      "r\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "h\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "m\n",
      "e\n",
      " \n",
      "s\n",
      "p\n",
      "e\n",
      "a\n",
      "k\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "l\n",
      "l\n",
      ":\n",
      "\n",
      "\n",
      "S\n",
      "p\n",
      "e\n",
      "a\n",
      "k\n",
      ",\n",
      " \n",
      "s\n",
      "p\n",
      "e\n",
      "a\n",
      "k\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "C\n",
      "i\n",
      "t\n",
      "i\n",
      "z\n",
      "e\n",
      "n\n",
      ":\n",
      "\n",
      "\n",
      "Y\n",
      "o\n",
      "u\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "l\n",
      "l\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "o\n",
      "l\n",
      "v\n",
      "e\n",
      "d\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "d\n",
      "i\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "n\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "f\n",
      "a\n",
      "m\n",
      "i\n",
      "s\n",
      "h\n",
      "?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "l\n",
      "l\n",
      ":\n",
      "\n",
      "\n",
      "R\n",
      "e\n",
      "s\n",
      "o\n",
      "l\n",
      "v\n",
      "e\n",
      "d\n",
      ".\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "o\n",
      "l\n",
      "v\n",
      "e\n",
      "d\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "C\n",
      "i\n",
      "t\n",
      "i\n",
      "z\n",
      "e\n",
      "n\n",
      ":\n",
      "\n",
      "\n",
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      ",\n",
      " \n",
      "y\n",
      "o\n",
      "u\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      " \n",
      "C\n",
      "a\n",
      "i\n",
      "u\n",
      "s\n",
      " \n",
      "M\n",
      "a\n",
      "r\n",
      "c\n",
      "i\n",
      "u\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "c\n",
      "h\n",
      "i\n",
      "e\n",
      "f\n",
      " \n",
      "e\n",
      "n\n",
      "e\n",
      "m\n",
      "y\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "e\n",
      "o\n",
      "p\n",
      "l\n",
      "e\n",
      ".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visualizing some chars from char_dataset\n",
    "for i in char_dataset.take(250):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tmd_y75emkwV"
   },
   "outputs": [],
   "source": [
    "# function to convert ids to text\n",
    "def idx2text(ids):\n",
    "  return ''.join([idx2char[i] for i in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qWdr_jYjh_lG",
    "outputId": "8f5add2b-f867-42f8-ce8c-130f1d14dafa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You \n",
      "are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you k\n",
      "now Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us ki\n",
      "ll him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be d\n",
      "one: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citi\n"
     ]
    }
   ],
   "source": [
    "# dividing the text into example sequences. Each input sequence will contain seq_length characters from the text.\n",
    "seq_length = 100\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "for item in sequences.take(5):\n",
    "  print(idx2text(item.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "apjhf8_uiL9t"
   },
   "outputs": [],
   "source": [
    "# For each sequence, we duplicated and shifted it to form the input and target text by using the `map` method to apply a simple function to each batch:\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ljjkw5Asj4qw",
    "outputId": "d4e8df54-5f2a-4d88-b748-d6fde89d6c53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:\n",
      " First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "---------------------------------------------------------------------\n",
      "Target data:\n",
      " irst Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You \n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data:\\n',idx2text(input_example.numpy()))\n",
    "  print(\"---------------------------------------------------------------------\")\n",
    "  print ('Target data:\\n',idx2text(target_example.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "I8PlgcgVkIVd"
   },
   "outputs": [],
   "source": [
    "# Shuffling the dataset and it into batches\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FBsF5ZxcvhAQ"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qXzf5GB0WeNP"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "model = build_model(vocab_size = len(vocab),embedding_dim=embedding_dim,rnn_units=rnn_units,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MR-R6ncA9AeI",
    "outputId": "5b2e20ec-1219-4fde-da07-0811260febc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           16640     \n",
      "                                                                 \n",
      " gru (GRU)                   (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4021569 (15.34 MB)\n",
      "Trainable params: 4021569 (15.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UOrJ4UrSWeHv",
    "outputId": "0027a4a9-ad62-482d-ab36-ed29ec2b24c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKnKgxHhWd-k",
    "outputId": "9baf17a4-5cd2-4750-9be7-b323dfa8ffea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44, 44,  2, 36, 36,  8,  9, 37, 16, 59, 19, 30, 30,  3,  2, 29, 32,\n",
       "        3, 40, 11,  6, 37, 28, 28,  4,  4, 25, 63, 31, 58, 58, 64, 50, 33,\n",
       "        7,  3, 30, 14, 45, 32, 25,  9, 42, 53, 43, 41, 38, 56, 18, 29, 63,\n",
       "       22, 55, 47,  9, 50,  2,  5, 20, 40, 61, 54, 29,  1, 62, 21, 17,  8,\n",
       "       13, 54, 21,  3, 10, 15, 46, 14, 13, 61,  5, 53, 39,  9,  2, 29,  3,\n",
       "       19,  8,  5, 34, 40,  2,  3, 61,  2, 49, 33, 18, 41,  3,  5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXSv-Nk3v73C",
    "outputId": "79891c10-d55a-43b9-c0ef-8cbda0fe23c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "  them;\n",
      "But how or in what place I do not know.\n",
      "\n",
      "KING RICHARD III:\n",
      "Come to me, Tyrrel, soon at after \n",
      "\n",
      "Next Char Predictions: \n",
      " ff!XX.3YDuGRR$!QT$b;,YPP&&MySttzlU-$RBgTM3doecZrFQyJqi3l!'HbwpQ xIE.ApI$:ChBAw'oa3!Q$G.'Vb!$w!kUFc$'\n"
     ]
    }
   ],
   "source": [
    "# Results from an untrained model\n",
    "print(\"Input: \\n\", idx2text(input_example_batch[0].numpy()))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", idx2text(sampled_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFr2ARxlZxuB",
    "outputId": "8ce010f8-26eb-450b-aacb-80cfe8b85e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.1738105\n"
     ]
    }
   ],
   "source": [
    "# defining the loss and calculating it before training\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-fZ91e3HZxq4"
   },
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ij6N6MWdZxkd",
    "outputId": "5547fd2e-5e82-4026-9ca1-462aa787856d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "172/172 [==============================] - 22s 61ms/step - loss: 2.6675\n",
      "Epoch 2/20\n",
      "172/172 [==============================] - 10s 49ms/step - loss: 1.9539\n",
      "Epoch 3/20\n",
      "172/172 [==============================] - 11s 52ms/step - loss: 1.6873\n",
      "Epoch 4/20\n",
      "172/172 [==============================] - 11s 51ms/step - loss: 1.5413\n",
      "Epoch 5/20\n",
      "172/172 [==============================] - 12s 51ms/step - loss: 1.4538\n",
      "Epoch 6/20\n",
      "172/172 [==============================] - 11s 51ms/step - loss: 1.3950\n",
      "Epoch 7/20\n",
      "172/172 [==============================] - 11s 53ms/step - loss: 1.3488\n",
      "Epoch 8/20\n",
      "172/172 [==============================] - 11s 53ms/step - loss: 1.3089\n",
      "Epoch 9/20\n",
      "172/172 [==============================] - 11s 54ms/step - loss: 1.2739\n",
      "Epoch 10/20\n",
      "172/172 [==============================] - 11s 55ms/step - loss: 1.2402\n",
      "Epoch 11/20\n",
      "172/172 [==============================] - 11s 55ms/step - loss: 1.2080\n",
      "Epoch 12/20\n",
      "172/172 [==============================] - 11s 56ms/step - loss: 1.1753\n",
      "Epoch 13/20\n",
      "172/172 [==============================] - 12s 57ms/step - loss: 1.1424\n",
      "Epoch 14/20\n",
      "172/172 [==============================] - 12s 58ms/step - loss: 1.1085\n",
      "Epoch 15/20\n",
      "172/172 [==============================] - 13s 60ms/step - loss: 1.0731\n",
      "Epoch 16/20\n",
      "172/172 [==============================] - 13s 61ms/step - loss: 1.0370\n",
      "Epoch 17/20\n",
      "172/172 [==============================] - 13s 61ms/step - loss: 1.0006\n",
      "Epoch 18/20\n",
      "172/172 [==============================] - 13s 59ms/step - loss: 0.9654\n",
      "Epoch 19/20\n",
      "172/172 [==============================] - 12s 57ms/step - loss: 0.9292\n",
      "Epoch 20/20\n",
      "172/172 [==============================] - 12s 58ms/step - loss: 0.8944\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history = model.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ZX4fckZjpB61"
   },
   "outputs": [],
   "source": [
    "# saving the model weights of the last epoch\n",
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikKtS7sg9ay1"
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vsqJsrjodwCT"
   },
   "outputs": [],
   "source": [
    "# building the model again with batch_size of 1 for prediction\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights('/content/model_weights.h5')\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wBDU8pbdy10",
    "outputId": "0d32a8b9-4277-467a-9144-93dde825a21c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (1, None, 256)            16640     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (1, None, 1024)           3938304   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, None, 65)             66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4021569 (15.34 MB)\n",
      "Trainable params: 4021569 (15.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "EuGVknnSnVol"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the word returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzCa7VS-pTWL",
    "outputId": "36d2cc49-1f85-4c8d-ce20-eed87d1efa46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: read we, having a villain, how near, the sunder Henry,\n",
      "And made alive to banished: and there's no marriage\n",
      "So think more struck thy charint. See how he stays\n",
      "Against the people, who taught\n",
      "The pedal hold of pride amazement.\n",
      "\n",
      "ESCALUT:\n",
      "Masters, and so did I, that kill'd your silly be denied, and thou hast queen.\n",
      "See, actor! Petrurest thou wert a king!\n",
      "Kindly, bid him be so cut off a hoopy days,\n",
      "Sin yet I know Itain, 'Pome to my breath:\n",
      "Now'd own goodness shall prove, you cannot thrush and thee but fear\n",
      "Their lips between twenty thousand now\n",
      "Have too much unwit for went. But, soft!\n",
      "\n",
      "GRUMIO:\n",
      "O this! how should the end o' the mind heremptruction:\n",
      "And throw this writ with extimpt of her woes I will choport\n",
      "Size on, and thou, the hand.\n",
      "\n",
      "LADY CAPULET:\n",
      "Here, most threatening stain alone,\n",
      "Rumourit, not calour Marcius and thou taught son!\n",
      "Ay, brave Mentury.\n",
      "\n",
      "First Servant:\n",
      "This man, have you lost swear as I talk of world.\n",
      "\n",
      "AUFIDIUS:\n",
      "My books i' the matter, hie your brother-aspect\n",
      "Men hat access o\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"ROMEO: \"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
